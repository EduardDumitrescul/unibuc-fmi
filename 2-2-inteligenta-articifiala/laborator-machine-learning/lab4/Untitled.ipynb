{
 "cells": [
  {
   "cell_type": "code",
   "id": "4665443b-9155-44a4-befe-af025b8e9e1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T11:35:02.474538Z",
     "start_time": "2024-06-07T11:35:02.468782Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "print(os.getcwd())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eduard/repos/unibuc-fmi/2-2-inteligenta-articifiala/laborator-machine-learning/lab4\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "9a4f2569-d772-45ef-992e-3bc90b7b5ef1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T11:35:02.562426Z",
     "start_time": "2024-06-07T11:35:02.475777Z"
    }
   },
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "603c802b-1fb4-4f5d-bd6d-9c5d86ca3006",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T11:35:14.722616Z",
     "start_time": "2024-06-07T11:35:14.705530Z"
    }
   },
   "source": [
    "training_sentences = np.load('training_sentences.npy', allow_pickle=True)\n",
    "test_sentences = np.load('test_sentences.npy', allow_pickle=True)\n",
    "training_labels = np.load('training_labels.npy', allow_pickle=True)\n",
    "test_labels = np.load('test_labels.npy', allow_pickle=True)\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "413b2c0f-4961-42fe-a379-476a7b4f013d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T11:35:16.108037Z",
     "start_time": "2024-06-07T11:35:16.104816Z"
    }
   },
   "source": [
    "print(test_sentences);"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['You', 'still', 'coming', 'tonight'])\n",
      " list(['HEY', 'BABE', 'FAR', '2', 'SPUNOUT', '2', 'SPK', 'AT', 'DA', 'MO', 'DEAD', '2', 'DA', 'WRLD', 'BEEN', 'SLEEPING', 'ON', 'DA', 'SOFA', 'ALL', 'DAY', 'HAD', 'A', 'COOL', 'NYTHO', 'TX', '4', 'FONIN', 'HON', 'CALL', '2MWEN', 'IM', 'BK', 'FRMCLOUD', '9', 'J', 'X'])\n",
      " list(['Ya', 'even', 'those', 'cookies', 'have', 'jelly', 'on', 'them'])\n",
      " ... list(['Just', 'havent', 'decided', 'where', 'yet', 'eh'])\n",
      " list(['Hmmmstill', 'we', 'dont', 'have', 'opener'])\n",
      " list(['Last', 'Chance', 'Claim', 'ur', 'Â£150', 'worth', 'of', 'discount', 'vouchers', 'today', 'Text', 'SHOP', 'to', '85023', 'now', 'SavaMob', 'offers', 'mobile', 'T', 'Cs', 'SavaMob', 'POBOX84', 'M263UZ', 'Â£300', 'Sub', '16'])]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "8f765bda-f816-40ed-a7e1-e5bb6a84411e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T11:35:17.033938Z",
     "start_time": "2024-06-07T11:35:17.030704Z"
    }
   },
   "source": [
    "def getWordDict(data):\n",
    "    d = dict()\n",
    "    index = 0\n",
    "    for list in data:\n",
    "        for word in list:\n",
    "            if d.get(word) is None:\n",
    "                index += 1\n",
    "                d[word] = index\n",
    "    return d\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "c25e615b-ff36-4bf4-b739-f6947cac770f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T11:35:18.303374Z",
     "start_time": "2024-06-07T11:35:18.299907Z"
    }
   },
   "source": [
    "def computeWordFrequence(data):\n",
    "    wordDict = getWordDict(data)\n",
    "    \n",
    "    freq = []\n",
    "    for l in data:\n",
    "        freq.append(list([wordDict[word] for word in l]))\n",
    "    return freq\n",
    "                   "
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "003345de-4f7e-412e-a206-1034ca05fe5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T11:35:19.205832Z",
     "start_time": "2024-06-07T11:35:19.202925Z"
    }
   },
   "source": [
    "print(computeWordFrequence(test_sentences[:10]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4], [5, 6, 7, 8, 9, 8, 10, 11, 12, 13, 14, 8, 12, 15, 16, 17, 18, 12, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37], [38, 39, 40, 41, 42, 43, 44, 45], [46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58], [59, 60, 61, 62, 50, 63, 64, 65], [66, 67, 67, 68, 69, 27, 70, 71, 72, 73, 8, 74, 75, 76, 48, 77, 78, 79, 80], [81, 82, 83, 84, 70, 85, 86, 82, 83, 87, 50, 88, 89, 90, 1, 85, 86, 91, 92], [93, 94, 95, 96, 50, 97, 61, 98, 61, 60, 99, 100, 101, 102, 103, 42, 104, 105, 106, 107, 108, 61, 109, 110, 73, 111, 100, 112, 113, 114, 115, 116], [117, 61, 54, 61, 118, 119, 120, 121], [84, 61, 122, 77, 123]]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "9e138714-70ff-41d2-8454-455406e4a7ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T11:35:20.006841Z",
     "start_time": "2024-06-07T11:35:20.003250Z"
    }
   },
   "source": [
    "def normalize_data(train_data, test_data, type=None):\n",
    "    train = computeWordFrequence(train_data)\n",
    "    test = computeWordFrequence(test_data)\n",
    "    \n",
    "    if type is None:\n",
    "        return train, test\n",
    "    if type=='standard':\n",
    "        train = [(sent - np.mean(sent)) / (np.std(sent) + 0.00000001) for sent in train]\n",
    "        test = [(sent - np.mean(sent)) / (np.std(sent) + 0.00000001) for sent in train]\n",
    "        return train, test\n",
    "\n",
    "        \n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "126a0d4b-1d3e-46e3-964d-40f61d393e01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T11:35:21.097140Z",
     "start_time": "2024-06-07T11:35:21.091829Z"
    }
   },
   "source": [
    "class BagOfWords:\n",
    "    def __init__(self):\n",
    "        self.vocabulary = dict()\n",
    "        self.words = []\n",
    "\n",
    "    def buildVocabulary(self, data):\n",
    "        self.words = []\n",
    "        self.vocabulary = dict()\n",
    "        index = 0\n",
    "        for list in data:\n",
    "            for word in list:\n",
    "                if self.vocabulary.get(word) is None:\n",
    "                    index += 1\n",
    "                    self.vocabulary[word] = index\n",
    "                    self.words.append(word)\n",
    "\n",
    "        print(len(self.words))"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "cc0f02e5-f2c8-4422-947f-b33632ffc62d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T11:35:22.123904Z",
     "start_time": "2024-06-07T11:35:22.113868Z"
    }
   },
   "source": [
    "bag = BagOfWords()\n",
    "bag.buildVocabulary(training_sentences)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9522\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c5d1c6a4fe68e82a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
