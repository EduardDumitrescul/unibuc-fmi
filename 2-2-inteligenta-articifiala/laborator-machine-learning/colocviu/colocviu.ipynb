{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b203e943a6e65975",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T09:06:10.800008Z",
     "start_time": "2024-06-08T09:06:09.748645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 140, 3)\n",
      "(1000, 140, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_filenames = []\n",
    "train_labels = []\n",
    "\n",
    "with open(\"V1/train.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[1:]:\n",
    "        line = line[:-1]\n",
    "        filename, label = line.split(',')\n",
    "        train_filenames.append(filename)\n",
    "        train_labels.append(label)\n",
    "        \n",
    "train_data = []\n",
    "for filename in train_filenames:\n",
    "    with open(f\"V1/{filename}\") as f:\n",
    "        lines = f.readlines()\n",
    "        img = []\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            pixel = [float(x) for x in line.split(',')]\n",
    "\n",
    "            pixel  =np.array(pixel)\n",
    "            img.append(pixel)\n",
    "        img = img[:140]\n",
    "        \n",
    "        img = np.array(img)\n",
    "        train_data.append(img)\n",
    "    \n",
    "    \n",
    "test_filenames = []\n",
    "test_labels = []\n",
    "\n",
    "with open(\"V1/test_labels.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[1:]:\n",
    "        line = line[:-1]\n",
    "        filename, label = line.split(',')\n",
    "        test_filenames.append(filename)\n",
    "        test_labels.append(label)\n",
    "        \n",
    "test_data = []\n",
    "for filename in train_filenames:\n",
    "    with open(f\"V1/{filename}\") as f:\n",
    "        lines = f.readlines()\n",
    "        img = []\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            pixel = [float(x) for x in line.split(',')]\n",
    "            pixel  =np.array(pixel)\n",
    "            \n",
    "            img.append(pixel)\n",
    "        \n",
    "        img = img[:140]\n",
    "        \n",
    "        img = np.array(img)\n",
    "        test_data.append(img)\n",
    "\n",
    "\n",
    "print(np.shape(train_data))\n",
    "print(np.shape(test_data))\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "test_data = np.array(test_data)\n",
    "\n",
    "std_train_data = (train_data - np.mean(train_data, axis=(0, 1))) / np.std(train_data, axis=(0, 1))\n",
    "std_test_data = (test_data - np.mean(test_data, axis=(0, 1))) / np.std(test_data, axis=(0, 1))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9c671885f0e27941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 140, 3)\n",
      "(1000, 4)\n",
      "Epoch 1/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7654 - loss: 0.6723   \n",
      "Epoch 2/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9387 - loss: 0.1949 \n",
      "Epoch 3/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9579 - loss: 0.1149 \n",
      "Epoch 4/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9761 - loss: 0.0899 \n",
      "Epoch 5/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9826 - loss: 0.0565 \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.9922 - loss: 0.0490\n",
      "Validation accuracy: 0.9929999709129333\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model_train_images = std_train_data.reshape(1000, 140, 3)\n",
    "print(np.shape(model_train_images))\n",
    "model_train_labels = to_categorical(train_labels, num_classes=4)\n",
    "print(np.shape(model_train_labels))\n",
    "\n",
    "\n",
    "\n",
    "my_model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(140, 3)),\n",
    "    Flatten(),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "my_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "my_model.fit(model_train_images, model_train_labels, epochs=5)\n",
    "\n",
    "loss, accuracy = my_model.evaluate(model_train_images, model_train_labels)\n",
    "print(f'Validation accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "294676204129446e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T09:07:18.501775Z",
     "start_time": "2024-06-08T09:07:18.495387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    }
   ],
   "source": [
    "prediction = my_model.predict(std_test_data)\n",
    "with open(\"Dumitrescul_EduardValentin_subiect1_solutia1.txt\", 'w') as f:\n",
    "    print(\"filename, label\", file=f)\n",
    "    for filename, pred in zip(test_filenames, prediction):\n",
    "        pred = np.argmax(pred)\n",
    "        print(f\"{filename},{pred}\", file=f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3fbe4e6104741a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4  2.75 4.1  5.45 6.8 ]\n",
      "[2 1 1 3 3 0 2 0 2 2]\n",
      "[1.4  2.75 4.1  5.45 6.8 ]\n",
      "[2 1 1 3 3 0 2 0 2 2]\n",
      "2 1\n",
      "1 1\n",
      "1 3\n",
      "3 3\n",
      "3 0\n",
      "0 2\n",
      "2 0\n",
      "0 2\n",
      "2 2\n",
      "[[0.         0.         1.         0.        ]\n",
      " [0.         0.5        0.         0.5       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.        ]\n",
      " [0.5        0.         0.         0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_filenames = []\n",
    "train_labels = []\n",
    "\n",
    "with open(\"V1/train.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[1:]:\n",
    "        line = line[:-1]\n",
    "        filename, label = line.split(',')\n",
    "        train_filenames.append(filename)\n",
    "        train_labels.append(label)\n",
    "        \n",
    "train_data = []\n",
    "for filename in train_filenames:\n",
    "    with open(f\"V1/{filename}\") as f:\n",
    "        lines = f.readlines()\n",
    "        img = []\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            pixel = [float(x) for x in line.split(',')]\n",
    "\n",
    "            pixel  =np.array(pixel)\n",
    "            img.append(pixel)\n",
    "        img = img[:140]\n",
    "        \n",
    "        img = np.array(img)\n",
    "        train_data.append(img)\n",
    "    \n",
    "    \n",
    "test_filenames = []\n",
    "test_labels = []\n",
    "\n",
    "with open(\"V1/test_labels.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[1:]:\n",
    "        line = line[:-1]\n",
    "        filename, label = line.split(',')\n",
    "        test_filenames.append(filename)\n",
    "        test_labels.append(label)\n",
    "        \n",
    "test_data = []\n",
    "for filename in train_filenames:\n",
    "    with open(f\"V1/{filename}\") as f:\n",
    "        lines = f.readlines()\n",
    "        img = []\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            pixel = [float(x) for x in line.split(',')]\n",
    "            pixel  =np.array(pixel)\n",
    "            \n",
    "            img.append(pixel)\n",
    "        \n",
    "        img = img[:140]\n",
    "        \n",
    "        img = np.array(img)\n",
    "        test_data.append(img)\n",
    "\n",
    "\n",
    "print(np.shape(train_data))\n",
    "print(np.shape(test_data))\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "test_data = np.array(test_data)\n",
    "\n",
    "std_train_data = (train_data - np.mean(train_data, axis=(0, 1))) / np.std(train_data, axis=(0, 1))\n",
    "std_test_data = (test_data - np.mean(test_data, axis=(0, 1))) / np.std(test_data, axis=(0, 1))\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "#EX2\n",
    "max = np.max(test_data)\n",
    "min = np.min(test_data)\n",
    "\n",
    "S = [5.2, 4.1, 3.1, 6.8, 6.8, 2.5, 5.2, 1.4, 4.2, 4.2]\n",
    "\n",
    "def value_to_bins(matrix, num_bins):\n",
    "    max = np.max(matrix)\n",
    "    min = np.min(matrix)\n",
    "    bins = np.linspace(start=min, stop=max+0.0000000000001, num=num_bins +1)\n",
    "    print(bins)\n",
    "    matrix = np.digitize(matrix, bins) - 1\n",
    "    return matrix\n",
    "\n",
    "def markov_one_dim(data, k=4):\n",
    "    arr = value_to_bins(data, k)\n",
    "    print(arr)\n",
    "    x = np.zeros((k, k))\n",
    "    for i in range(1, len(arr)):\n",
    "        print(arr[i-1], arr[i])\n",
    "        x[arr[i-1]][arr[i]] += 1\n",
    "    for i in range(len(x)):\n",
    "        x[i] /= np.sum(x[i])\n",
    "    return x\n",
    "\n",
    "def markov(data, k=4):\n",
    "    x = data[:,:0]\n",
    "    y = data[:,:,1]\n",
    "    z = data[:,:,:2]\n",
    "    x = marok_one_dim(x, k)\n",
    "    y= marok_one_dim(y, k)\n",
    "    z = marok_one_dim(z, k)\n",
    "\n",
    "    # return x + y + z\n",
    "\n",
    "print(value_to_bins(S, 4))\n",
    "print(markov_one_dim(S, 4))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5592e1-5720-4103-8551-6263318c243c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
