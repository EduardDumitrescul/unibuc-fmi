\documentclass[12pt]{article}
\usepackage[T1]{fontenc}
\usepackage{newtxtext,newtxmath}
\usepackage{setspace}
\doublespacing 
\usepackage{geometry}
\geometry{margin=1in}
\begin{document}

\title{The Limits of Cognitive Reach: Why the Mind is Not a Seamless Web}
\author{Eduard-Valentin Dumitrescul}
\date{23 December 2025}

\maketitle

\textit{The Extended Mind\cite{the-extended-mind}}is a new concept that aims to fundamentally
change our view of the world, brain and even our own identity. Introduced by Clark and
Chalmers, it uses the parity principle, coupling and active externalism to support the idea that
the mind is not bounded by skin and skull and can extend into the world and into the 
objects we use to aid our cognitive processes. 


\textit{The Extended Mind} idea already has a multitude of critics, most notable being J. Fodor, 
F. Adams, K.Aizawa and R. Rupert. While this new view may be truly revolutionary,
its argumentation seems inconsistent and lacks the power to support it.
This essay aims to identify and analyze specific conceptual gaps within the functionalist
framework of the Extended Mind.
It is important to note that the goal of this essay is not a disproof of the notion of
\textit{The Extended Mind} \textemdash a task that may be premature given the evolving
understanding of neurobiology. Rather, this critique focuses on the logical inconsistencies
of the framework itself.
F. Adams and K. Aizawa cynically said in their 
\textit{"The Bounds of Cognition"}\cite{the-bounds-of-cognition}:
\begin{quote}
    In this paper, we propose to defend common sense. (Adams, Aizawa, 2001, p. 46)
\end{quote}


\section{The Parity Principle: A Rhetorical Sleight of Hand}

\subsection{Tetris}

The Parity Principle is a concept of fairness that is very often met in Law to ensure 
that "like cases should be treated alike". This is a tool that can be effectively employed
in philosophical debate, as Clark and Chalmers demonstrated in their examples.
They start by proposing a thought experiment inspired by the game Tetris:

\begin{quotation}
    (1) A person sits in front of a computer screen which displays images of various
    two-dimensional geometric shapes and is asked to answer questions concerning the 
    potential fit of such shapes into depicted ''sockets''. To assess fit, the
    person must mentally rotate the shapes to align them with the sockets.


    (2) A person sits in front of a similar computer screen, but this time can choose
    either to physically rotate the image on the screen, by pressing a rotate button,
    or to mentally rotate the image as before. We can also suppose, not unrealis-
    tically, that some speed advantage accrues to the physical rotation operation.


    (3) Sometime in the cyberpunk future, a person sits in front of a similar computer
    screen. This agent, however, has the benefit of a neural implant which can
    perform the rotation operation as fast as the computer in the previous
    example. The agent must still choose which internal resource to use (the
    implant or the good old fashioned mental rotation), as each resource makes
    different demands on attention and other concurrent brain activity. How
    much cognition is present in these cases? We suggest that all three cases are
    similar. Case (3) with the neural implant seems clearly to be on a par with
    case (1). And case (2) with the rotation button displays the same sort of
    computational structure as case (3), distributed across agent and computer
    instead of internalized within the agent. If the rotation in case (3) is cognitive,
    by what right do we count case (2) as fundamentally different? We cannot
    simply point to the skin/skull boundary as justification, since the legitimacy of
    that boundary is what is at issue. But nothing else seems different. (Clark \&
    Chalmers, 1998, p. 1)
\end{quotation}

While Clark and Chalmers argue these scenarios are computationally similar,
Adams and Aizawa consider that significant differences have been omitted. Scenario (1)
involves non derived-content in the form of mental representations, whereas the scenario (2)
makes use of an electrical circuit that actually rotates the shapes, not some
representations.

Moreover, the choice available in the second scenario is an artificial way of 
bridging the gap between the two, by creating a sense of closeness. 
It is a totally separate cognitive process that does not interfere with the other,
thus, for a clear and fair representation, it could have been omitted.

Scenario (3) differs from the second only in terms of location. Now, the tool the person
can use is placed inside their body, taking the form of an implant. It is easier to agree
that these two cases are very similar in terms of the cognitive process being employed.
However, there is no strong evidence of the rotation in the third scenario being 
cognitive. The actual thought process may consist of the following steps: the person decides
that they want to rotate the shape, the effort of rotating the shape is delegated
to the implant, which produces an output. Then, the person makes another decision based on 
observing that output. Now, if we consider the effort done by the implant to be cognitive, then we ought to 
also admit that other electrical circuits used for a task are cognitive. 

Even when the tool is reliably available and automatically endorsed, it lacks what Adams 
and Aizawa call 'intrinsic content'. A such notebook still needs an external interpreter that
assigns meaning to it, while a biological brain does not. By ignoring this distinction, 
The Parity Principle mixes information processing with cognitive experience.

\subsection{The Notebook}

The second thought experiment proposed by Clark and Chalmers introduce two characters. Inga and Otto
both of whom want to visit the Museum of Modern Art, found on 53rd Street. In order to achieve this, 
they need to know where to go, so Inga consults her memory. Otto, suffering from Alzheimer's
disease, consults his notebook, where at some point he wrote down the address. The
argument made here is that in both cases, the belief of where the museum is located is
identical, no matter whether is internalised or externalised and exists before Inga accesses
her memory, respectively Otto his notebook.

To demonstrate the conceptual fragility of this parity, we must examine the architecure of 
these two examples. If Otto suddenly loses his sight he can no longer "remember" 
the address. If we follow this logic, we are forced to conclude that the eyes are more than 
sensory organs, but parts of the cognitive process of the retrieval of information.
In the same manner, if the notebook had been written in Braille, the same logic would require 
us to conclude that the tactile receptors are "cognitive"

A more realistic explanation of the initial Inga and Otto scenarios is that the 
notebook, like the memory, is a source of information. It is not necessarily tied to
cognition, it just acts as a tool. Whether our biological memory is part of the cognition
is another topic, but, for the sake of our argument, the answer should not matter. Otherwise, 
we could conclude that every source of information is cognitive.


\section{The Parasitic Nature Of Tools}
It seems that Clark and Chalmers confuse \textit{Coupling} with \textit{Consitution}. This was 
best described by Adams and Aizawa (2001).

To summarize the idea, coupling is the bringing together of multiple systems to solve a task 
\textemdash like a diver using an oxygen tank. While the diver and the oxygen tank form a "coupled
system", it would be erroneous to say the oxygen tank is part of the diver's biological 
respiratory system.

To add a new face to this issue, it can be argued that the use of tools, while helping in the
immediate, may harm the agent in the long term. This suggests a parasitic rather than a symbiotic
relationship. The most recent example is the use of Large Language Models (LLMs). 
As observed in \textit{Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI
Assistant for Essay Writing Task} \cite{kosmyna2025arxiv}, the group that used LLMs to write an
essay were able to correctly quote 11\% of the time, while the control group 78\%.
In case of Inga, if she stopped using her memory and started relying solely on a notebook, her capacity
to remember information would drop over time.  

Another example is the use of GPS for navigation. While Clark and Chalmers would argue that 
a GPS device serves as an external cognitive resource, empirical evidence suggests the 
relationship is subtractive. Habitual GPS use has been shown to reduce activity in the 
hippocampus—the area of the brain responsible for spatial memory 
(Dahmani \& Bohbot, 2020, \cite{dahmani2020gps}).

If the GPS were truly a "constituent" of the mind, the agent's total navigational capacity 
should remain constant. Instead, we observe a "use-it-or-lose-it" effect: as the tool takes over 
the cognitive load, the biological abilities weaken. This supports the "parasitic" 
hypothesis: the tool does not expand the mind's boundaries; it replaces its core functions, 
leaving the agent in a state of cognitive dependency. While this can still be seen as an improvement
over the biological mind alone, we ought to acknowledge the diminishing returns of the use of some.
external aids, while also becoming less autonomous.

\section{Challenging Bioprejudice}

An \textit{Extended Mind} proponent would likely argue that the "parasitic" critique offered in the 
previous section is rooted in bioprejudice \textemdash a preference for biological neurons
over technological equivalents. Andy Clark often uses the analogy of a prosthetic limb that,
even though causes muscle atrophy, is still considered as part of the motor system because it 
performs the exactly same function as its biological counterpart.  From this perspective, the atrophy
of the hippocampus is an efficient reallocation of resources.

However, this objection does not consider the problem of derived intentionality. While the 
prosthetic might be fully functional, it does not create meaning, as the movement is completely
dependent on the biological motor cortex.

This lead to a critical counter-argument: if we consider the tool as being part of the mind, we 
must also accept a state of absolute dependency that differs from the biological memory. 
Even if Inga temporarily forgets the address, the neural pathways representing that concept are 
still present. On the other hand, if Otto loses his notebook, the information is irreversibly 
erased. The difference between the capacity to think and the storing of information must be 
acknowledged, the biological mind being the only one capable to 'understand'.

\section{Fragility and the Legal Collapse}
As Fodor identified, this interpretation of the mind creates a slippery slope toward 
cognitive bloat\cite{fodor2009} \textemdash and potentially panpsychism—the notion that the world itself becomes the mind. 
While many examples suggest this, even more arise when we apply this logic to the legal and 
digital domains.

Consider the assumption that if a notebook serves the same functional purpose for Otto as
biological memory does for Inga, then both must be viewed as constitutive parts of their 
respective cognitive systems. Following this logic, Otto losing his notebook is functionally 
equivalent to Inga suffering a traumatic brain injury. If a third party caused these situations,
should a thief be prosecuted for battery or "mental interference" rather than mere property 
theft? Furthermore, if a thief reads Otto's "thoughts" in the notebook and commits a crime, 
who bears the responsibility? Whose cognition does the notebook belong to in that moment?

In case of a process, there is a clear distinction between "testimonials" and "physical evidence".
One cannot be a witness against himself. If we believe the notebook to be part of Otto's mind, 
then that cannot be used as evidence, as it would be a violation against the right 
of self-incrimination.

This becomes even more pressing with the increasing use of Artificial Intelligence. From the 
perspective of Clark and Chalmers, these models are integrated into our cognition. But this 
raises a "persistence" problem: if the server hosting the AI crashes, is the user suffering 
a temporary cognitive disability? If we accept the \textit{Extended Mind}, then internet access
and server uptime become fundamental human rights.

\section{Consequences}

At stake in this \textit{Extended Mind} debate is the very definition of the human identity.
By removing the line between the biological self and technological tools, we risk to diminish the
value of the internal cognitive effort. We lose our thinking independency and start outsourcing
every mental process. Autonomous critical thinking becomes synonymous with an agent that uses external 
interfaces. Moreover, instead of us being the agents and technology being the tool, the roles
reverse and we become nodes in an enourmous \textit{cognitive network}.

Out understanding of morality becomes blurred, as seen in the theft and Artificial Intelligence 
example. The laws that govern societies, built upon morality, are challanged. Only 
because the \textit{Mind} starts to mean eveything and nothing at the same time.

\section{Conclusion}

While the \textit{Extended Mind} thesis proposes a new, innovative vision of the boundaryless mind, 
a detailed analysis reveals a framework that is built on inconsistencies. By saying that the tools 
used by the cognitive processes are equal to the congnitive systems that employ them, we risk 
the dilution of the term \textit{Mind}. As presented previously, The Parity Principle 
often relies on rhetorical exercise that ignore fundamental differences between biological organism 
and artificial mechanisms. 
Furthermore, the transition from "coupling" to "constitution" is more than a philosophical debate.
It has profound implications on what we consider \textit{indentity}, \textit{agency}, and even the 
underlying mechanisms of our current societies. Recent discoveries demonstrate that the tools 
we use are not even always an extension of our minds, but replacements, which have the ability to 
weaken our autonomy.
Utlimately, the \textit{Extended Mind} does not just expand the mind, it dissolves the individual.
Humans become a temporary collection of tools and neurons and critical thinking loses its locus.


\bibliographystyle{plain} 
\bibliography{references}

\end{document}


